from torch import tensor,load
from jieba import cut
import jieba.analyse
import time
jieba.load_userdict("NLP/userdict.txt")

"""
æ¨¡å‹è©•è«–åˆ†æ
"""
#   åˆ†è©åŠç·¨ç¢¼
def inp_tokenization(input_str,word_to_id):
    inp_to_jieba = ','.join(cut(input_str, cut_all=False, HMM=True))

    input_vec = []
    inp_to_jieba = inp_to_jieba.split(',')
    for char in inp_to_jieba:
        if char not in word_to_id:
            input_vec.append(0)
        else:
            input_vec.append(word_to_id[char])
    return input_vec

#   é æ¸¬åº—å®¶ç¨®é¡   
def predict_type(input_str):
    from NLP.Program.NLPProgram.torch_dataloader_type import create_dataloader,load_data
    
    device, model=create_dataloader()
        
    label_to_id,id_to_label,word_to_id,id_to_word,\
        = load_data("complete.pkl")
        
    input_vec = inp_tokenization(input_str,word_to_id)
        
    model.load_state_dict(load("NLP/model_type.pkl"))
    model.eval()
    
    # convert to tensor
    sentences = tensor(input_vec).view(1, -1).to(device)
    mask = (sentences > 0).to(device)
    paths = model(sentences, mask)
    # print("åˆ¤åˆ¥åº—å®¶ç‚ºï¼š " , paths[0][0])
    
    return paths[0][0]

#   é æ¸¬å¥½å£è©•è«–
def predict_comment_analyse(input_str):
    from NLP.Program.NLPProgram.torch_dataloader_comment import create_dataloader,load_data
    
    device,model=create_dataloader()
        
    label_to_id,id_to_label,word_to_id,id_to_word,\
         = load_data("complete.pkl")
    
    input_vec = inp_tokenization(input_str,word_to_id)
    model.load_state_dict(load("NLP/model_comment.pkl"))
    model.eval()
    
    # convert to tensor
    sentences = tensor(input_vec).view(1, -1).to(device)
    mask = (sentences > 0).to(device)
    paths = model(sentences, mask)
    # print("åˆ¤åˆ¥è©•è«–ç‚ºï¼š " , paths[0][0])
    
    return paths[0][0]

#   åŸ·è¡Œæ‰‹å‹•è¼¸å…¥ä¸¦å¾—å‡ºçµæœ
def run(input_str):
    print("åŠ è¼‰æ™‚é–“é–‹å§‹      ï¼š ", time.ctime())
    from spt.speech import speech_to_text
    print("åŠ è¼‰å®Œæˆspeechæ™‚é–“ï¼š ", time.ctime())
    from spt.tts import say
    print("åŠ è¼‰å®Œæˆttsæ™‚é–“   ï¼š ", time.ctime())
    
    while True:
        if input_str == "":
            input_str = speech_to_text()    
            if input_str == "çµæŸåˆ†æ":break
            print(input_str)
        
        
        result_comment = predict_comment_analyse(input_str)
        result_type = predict_type(input_str)
        
        id_to_label = {"1":"bad review","2":"good review","3":"Hostel","4":"Restaurant","5":"KTV"}
        
        category = id_to_label[str(result_type)]
        review = id_to_label[str(result_comment)]
        
        print("æå–è©•è«–ï¼š ",input_str)
        print("å•†å®¶ç¨®é¡ï¼š ",category)
        print("å¥½å£è©•è«–ï¼š ",review)
        say ("{} and {}".format(category , review))
        print("=========================================================================================================================================")
          
#   åŸ·è¡Œå¤šå€‹è©•è«–åˆ†æ
def comment_list():
    A = "è¶…å‘¼æƒ³åƒçš„é¤å»³ å¥½åƒ æ–™å¯¦åœ¨æ–°é®®ã€‚æ¹¯é ­å¾ˆæ£’ã€‚ä¸‹æ¬¡é‚„è¦ä¾†" 
    B = "ç”¨é¤å‰æœªå‘ŠçŸ¥èœå–®è¨»æ˜æœ‰ç”œé»âŒå¯¦éš›ä¸¦æ²’æœ‰ï¼ˆè£œä¸€ç“¶é¤Šæ¨‚å¤š???ï¼‰é€™æ˜¯ä»€éº¼æ„æ€???è‡ªåŠ©å§æ²’æœ‰çˆ†ç±³èŠ±ã€å†°æ·‡æ·‹âŒ"
    C = "éå¸¸æ„Ÿè¬å„å€‹æœå‹™äººå“¡çš„è¦ªåˆ‡èˆ‡è¾›å‹ï¼Œèƒ½å¤ ä½åœ¨é€™é‚Šæˆ‘è¦ºå¾—éå¸¸å¹¸é‹ï¼Œä¸­é–“æ›¾ç¶“å› ç‚ºç§äººå› ç´ éœ€è¦å»¶é•·å…¥ä½æ™‚é–“ï¼Œä½†æ«ƒæª¯æœå‹™äººå“¡ä¹Ÿæ²’æœ‰å«Œéº»ç…©ï¼Œåè€Œæ¯æ¬¡æ¥è½é›»è©±éƒ½éå¸¸çš„æœ‰è€å¿ƒã€‚"
    D = "é…’åº—ç¶²è·¯å·®ä¸”ç¶“å¸¸è·³æ‰ï¼Œæœå‹™äººå“¡æ…‹åº¦ä¸ä½³ï¼Œé£Ÿç‰©è®ŠåŒ–å¤šï¼Œä½†æ™šé¤éƒ½è¼ƒä¸å„ªã€‚æä¾›å¤–é€æœå‹™ï¼Œä¸éé€ä¸Šä¾†çš„æ™‚é–“éƒ½éå¸¸ä¸ä¸€å®šã€‚"
    E = "å¾ˆä¸éŒ¯çš„åœ°æ–¹ï¼Œæ¯æ¬¡æ—©ä¸€é»å»æœƒå“¡éƒ½å¯ä»¥å”±5å€‹å°æ™‚ï¼Œæœ‰ä¾›é¤ï¼Œæ°´é¤ƒè¶…å¥½åƒğŸ‘ğŸ‘ğŸ‘"
    F = "å…¨é¢ç¦è¸,ä½†æ˜¯ä¸€åŠä»¥ä¸Šçš„åŒ…å»‚å’Œå“¡å·¥éƒ½åœ¨æŠ½è¸çš„åœ°æ–¹,æœ¬ä¾†æƒ³èªªç¦ç…™æ‰ä¾†,ä¸€ä¸Šå»å°±æ˜¯å—†é¼»çš„è¸å‘³,å”±åˆ°ä¸€åŠé‚„æœ‰äººåœ¨é–€å£é–‹æŠ½ï¼Ÿï¼Ÿï¼Ÿ"

        

# comment_list()

